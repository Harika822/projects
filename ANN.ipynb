{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOPyn2d7qg/Wa9A4fcRS+6Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harika822/projects/blob/master/ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q3_qplm18nQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def nonlin(x,deriv=False):\n",
        " if(deriv==True):\n",
        "  return x*(1-x)\n",
        " return 1/(1+np.exp(-x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Snj64a22TYM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "17c89154-b868-49ff-bde7-7433ba9fa509"
      },
      "source": [
        "x=np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
        "y=np.array([[0,0,1,1]]).T\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 3)\n",
            "(4, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yL_ZsRt21fv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "267ad75e-0887-4fd2-d220-924f9cdc8d30"
      },
      "source": [
        "#@title Default title text\n",
        "#since there are 3 layers we took 3,1\n",
        "rands=np.random.random((3,1))\n",
        "print(rands)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.4173048 ]\n",
            " [0.55868983]\n",
            " [0.14038694]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0hu7ruS3A8y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a56765bf-119e-4b53-bbd2-436412279023"
      },
      "source": [
        "np.random.seed(1)\n",
        "#initialize weights randomly using weights\n",
        "#1 hidden,3 inputs ,1 output\n",
        "syn0=2*np.random.random((3,1)) -1\n",
        "print(syn0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.16595599]\n",
            " [ 0.44064899]\n",
            " [-0.99977125]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPGzBca63xWc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "1c9dfed4-f10e-4c12-849e-6b364cfa93b3"
      },
      "source": [
        "for iter in range(100000):\n",
        " l0=x\n",
        " l1=nonlin(np.dot(l0,syn0))\n",
        " l1_error= y - l1\n",
        " l1_delta=l1_error*nonlin(l1,True)\n",
        " syn0+=np.dot(l0.T,l1_delta)\n",
        "print(\"output after training\")\n",
        "print(l1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output after training\n",
            "[[0.00301758]\n",
            " [0.00246109]\n",
            " [0.99799161]\n",
            " [0.99753723]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtE2G_XqBKde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#program for 3 layer network\n",
        "import numpy as np\n",
        "def nonlin(x,deriv=False):\n",
        "  if(deriv==True):\n",
        "    return x*(1-x)\n",
        "  return 1/(1+np.exp(-x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHaHulJnB5iR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
        "y=np.array([[0],[1],[1],[0]])\n",
        "np.random.seed(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sy2XnjHCPdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "syn0=2*np.random.random((3,4)) - 1\n",
        "syn1=2*np.random.random((4,1)) - 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE8MFjB7CopE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "6b363c42-8573-4bdf-a2ff-7dc2d38c5005"
      },
      "source": [
        "#feed forward and feed back propagation\n",
        "for j in range(60000):\n",
        "  l0=x\n",
        "  l1=nonlin(np.dot(l0,syn0))\n",
        "  l2=nonlin(np.dot(l1,syn1))\n",
        "  l2_error=y-l2\n",
        "  if(j%10000)==0:\n",
        "    print(\"error:\"+ str(np.mean(np.abs(l2_error))))\n",
        "  l2_delta=l2_error*nonlin(l2,deriv=True)\n",
        "  l1_error=l2_delta.dot(syn1.T)\n",
        "  l1_delta=l1_error*nonlin(l1,deriv=True)\n",
        "  syn1+=l1.T.dot(l2_delta)\n",
        "  syn0+=l0.T.dot(l1_delta)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "error:0.4964100319027255\n",
            "error:0.008584525653247157\n",
            "error:0.0057894598625078085\n",
            "error:0.004629176776769985\n",
            "error:0.0039587652802736475\n",
            "error:0.003510122567861678\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RViJCsrGIXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sklearn,mlp clasifier algorithm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhhOl0mOHFL3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "e0b2fbe0-a657-48cf-dfe6-b99906d45874"
      },
      "source": [
        "spine=pd.read_csv(\"Dataset_spine.csv\")\n",
        "spine.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pelvic_incidence</th>\n",
              "      <th>pelvic_tilt</th>\n",
              "      <th>lumbar_lordosis_angle</th>\n",
              "      <th>sacral_slope</th>\n",
              "      <th>pelvic_radius</th>\n",
              "      <th>degree_spondylolisthesis</th>\n",
              "      <th>pelvic_slope</th>\n",
              "      <th>Direct_tilt</th>\n",
              "      <th>thoracic_slope</th>\n",
              "      <th>cervical_tilt</th>\n",
              "      <th>sacrum_angle</th>\n",
              "      <th>scoliosis_slope</th>\n",
              "      <th>Class_att</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63.027818</td>\n",
              "      <td>22.552586</td>\n",
              "      <td>39.609117</td>\n",
              "      <td>40.475232</td>\n",
              "      <td>98.672917</td>\n",
              "      <td>-0.254400</td>\n",
              "      <td>0.744503</td>\n",
              "      <td>12.5661</td>\n",
              "      <td>14.5386</td>\n",
              "      <td>15.30468</td>\n",
              "      <td>-28.658501</td>\n",
              "      <td>43.5123</td>\n",
              "      <td>Abnormal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>39.056951</td>\n",
              "      <td>10.060991</td>\n",
              "      <td>25.015378</td>\n",
              "      <td>28.995960</td>\n",
              "      <td>114.405425</td>\n",
              "      <td>4.564259</td>\n",
              "      <td>0.415186</td>\n",
              "      <td>12.8874</td>\n",
              "      <td>17.5323</td>\n",
              "      <td>16.78486</td>\n",
              "      <td>-25.530607</td>\n",
              "      <td>16.1102</td>\n",
              "      <td>Abnormal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>68.832021</td>\n",
              "      <td>22.218482</td>\n",
              "      <td>50.092194</td>\n",
              "      <td>46.613539</td>\n",
              "      <td>105.985135</td>\n",
              "      <td>-3.530317</td>\n",
              "      <td>0.474889</td>\n",
              "      <td>26.8343</td>\n",
              "      <td>17.4861</td>\n",
              "      <td>16.65897</td>\n",
              "      <td>-29.031888</td>\n",
              "      <td>19.2221</td>\n",
              "      <td>Abnormal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   pelvic_incidence  pelvic_tilt  ...  scoliosis_slope  Class_att\n",
              "0         63.027818    22.552586  ...          43.5123   Abnormal\n",
              "1         39.056951    10.060991  ...          16.1102   Abnormal\n",
              "2         68.832021    22.218482  ...          19.2221   Abnormal\n",
              "\n",
              "[3 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeEvLwj2HOQI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "d5a9e49c-d594-4f2e-d942-701449c667a3"
      },
      "source": [
        "spine.describe()\n",
        "spine.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['pelvic_incidence', 'pelvic_tilt', 'lumbar_lordosis_angle',\n",
              "       'sacral_slope', 'pelvic_radius', 'degree_spondylolisthesis',\n",
              "       ' pelvic_slope', ' Direct_tilt', 'thoracic_slope', 'cervical_tilt',\n",
              "       'sacrum_angle', 'scoliosis_slope', 'Class_att'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRiUSx0oHSKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spine=spine.drop([' pelvic_slope',' Direct_tilt',\"thoracic_slope\",\"cervical_tilt\",\"sacrum_angle\",\n",
        "\"scoliosis_slope\"],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z4xx_c3H0EX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "5716da91-4f1c-4af5-bc5d-57559e31868c"
      },
      "source": [
        "spine.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['pelvic_incidence', 'pelvic_tilt', 'lumbar_lordosis_angle',\n",
              "       'sacral_slope', 'pelvic_radius', 'degree_spondylolisthesis',\n",
              "       'Class_att'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6LuFTQIH2UH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juJMtwwZIPlP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=spine['Class_att']\n",
        "x=spine.drop(['Class_att'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgpaqGbvJJKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=27)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mzMTqtkJV7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf=MLPClassifier(activation='tanh',hidden_layer_sizes=(100,100,100),max_iter=500,alpha=0.0001,\n",
        "                  solver='sgd',verbose=10,random_state=21,tol=0.000000001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuiyFgDEJ1IY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7bdba523-b848-40e5-b5c0-ba76d1ced84b"
      },
      "source": [
        "clf.fit(x_train,y_train)\n",
        "y_pred=clf.predict(x_test)\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.90341222\n",
            "Iteration 2, loss = 0.82114232\n",
            "Iteration 3, loss = 0.73665584\n",
            "Iteration 4, loss = 0.67098267\n",
            "Iteration 5, loss = 0.63769296\n",
            "Iteration 6, loss = 0.61915358\n",
            "Iteration 7, loss = 0.61158041\n",
            "Iteration 8, loss = 0.60117788\n",
            "Iteration 9, loss = 0.58660380\n",
            "Iteration 10, loss = 0.56641775\n",
            "Iteration 11, loss = 0.54736953\n",
            "Iteration 12, loss = 0.53167414\n",
            "Iteration 13, loss = 0.52019545\n",
            "Iteration 14, loss = 0.51147031\n",
            "Iteration 15, loss = 0.50536264\n",
            "Iteration 16, loss = 0.49919846\n",
            "Iteration 17, loss = 0.49274914\n",
            "Iteration 18, loss = 0.48596328\n",
            "Iteration 19, loss = 0.47987481\n",
            "Iteration 20, loss = 0.47405804\n",
            "Iteration 21, loss = 0.46959056\n",
            "Iteration 22, loss = 0.46545457\n",
            "Iteration 23, loss = 0.46045435\n",
            "Iteration 24, loss = 0.45657333\n",
            "Iteration 25, loss = 0.45280010\n",
            "Iteration 26, loss = 0.44895525\n",
            "Iteration 27, loss = 0.44534964\n",
            "Iteration 28, loss = 0.44133704\n",
            "Iteration 29, loss = 0.43758415\n",
            "Iteration 30, loss = 0.43492872\n",
            "Iteration 31, loss = 0.43148026\n",
            "Iteration 32, loss = 0.42878495\n",
            "Iteration 33, loss = 0.42602739\n",
            "Iteration 34, loss = 0.42360133\n",
            "Iteration 35, loss = 0.42115719\n",
            "Iteration 36, loss = 0.41821331\n",
            "Iteration 37, loss = 0.41466164\n",
            "Iteration 38, loss = 0.41082086\n",
            "Iteration 39, loss = 0.40732042\n",
            "Iteration 40, loss = 0.40383137\n",
            "Iteration 41, loss = 0.40124950\n",
            "Iteration 42, loss = 0.39722385\n",
            "Iteration 43, loss = 0.39421691\n",
            "Iteration 44, loss = 0.39176617\n",
            "Iteration 45, loss = 0.38936807\n",
            "Iteration 46, loss = 0.38641730\n",
            "Iteration 47, loss = 0.38342603\n",
            "Iteration 48, loss = 0.38155241\n",
            "Iteration 49, loss = 0.37973039\n",
            "Iteration 50, loss = 0.37829247\n",
            "Iteration 51, loss = 0.37600361\n",
            "Iteration 52, loss = 0.37395657\n",
            "Iteration 53, loss = 0.37193909\n",
            "Iteration 54, loss = 0.37023059\n",
            "Iteration 55, loss = 0.36851789\n",
            "Iteration 56, loss = 0.36745912\n",
            "Iteration 57, loss = 0.36496558\n",
            "Iteration 58, loss = 0.36130727\n",
            "Iteration 59, loss = 0.36059062\n",
            "Iteration 60, loss = 0.35902105\n",
            "Iteration 61, loss = 0.35610104\n",
            "Iteration 62, loss = 0.35510107\n",
            "Iteration 63, loss = 0.35327712\n",
            "Iteration 64, loss = 0.35186342\n",
            "Iteration 65, loss = 0.35104837\n",
            "Iteration 66, loss = 0.35028882\n",
            "Iteration 67, loss = 0.34847217\n",
            "Iteration 68, loss = 0.34663755\n",
            "Iteration 69, loss = 0.34500911\n",
            "Iteration 70, loss = 0.34433926\n",
            "Iteration 71, loss = 0.34425010\n",
            "Iteration 72, loss = 0.34359751\n",
            "Iteration 73, loss = 0.34042034\n",
            "Iteration 74, loss = 0.33940565\n",
            "Iteration 75, loss = 0.33954007\n",
            "Iteration 76, loss = 0.33689560\n",
            "Iteration 77, loss = 0.33483660\n",
            "Iteration 78, loss = 0.33599011\n",
            "Iteration 79, loss = 0.33389001\n",
            "Iteration 80, loss = 0.33290544\n",
            "Iteration 81, loss = 0.32835662\n",
            "Iteration 82, loss = 0.32701245\n",
            "Iteration 83, loss = 0.32686989\n",
            "Iteration 84, loss = 0.32301803\n",
            "Iteration 85, loss = 0.32067120\n",
            "Iteration 86, loss = 0.32003265\n",
            "Iteration 87, loss = 0.31892549\n",
            "Iteration 88, loss = 0.31950869\n",
            "Iteration 89, loss = 0.31780306\n",
            "Iteration 90, loss = 0.32414316\n",
            "Iteration 91, loss = 0.33654633\n",
            "Iteration 92, loss = 0.32165410\n",
            "Iteration 93, loss = 0.31405728\n",
            "Iteration 94, loss = 0.31578102\n",
            "Iteration 95, loss = 0.31961428\n",
            "Iteration 96, loss = 0.31027306\n",
            "Iteration 97, loss = 0.31009742\n",
            "Iteration 98, loss = 0.30914492\n",
            "Iteration 99, loss = 0.30951368\n",
            "Iteration 100, loss = 0.30709376\n",
            "Iteration 101, loss = 0.30655829\n",
            "Iteration 102, loss = 0.31191791\n",
            "Iteration 103, loss = 0.30479538\n",
            "Iteration 104, loss = 0.30490617\n",
            "Iteration 105, loss = 0.30596904\n",
            "Iteration 106, loss = 0.30187604\n",
            "Iteration 107, loss = 0.30190769\n",
            "Iteration 108, loss = 0.30122291\n",
            "Iteration 109, loss = 0.30190304\n",
            "Iteration 110, loss = 0.30773456\n",
            "Iteration 111, loss = 0.30799028\n",
            "Iteration 112, loss = 0.29937528\n",
            "Iteration 113, loss = 0.30351004\n",
            "Iteration 114, loss = 0.29715549\n",
            "Iteration 115, loss = 0.29491622\n",
            "Iteration 116, loss = 0.29337319\n",
            "Iteration 117, loss = 0.29387124\n",
            "Iteration 118, loss = 0.29473581\n",
            "Iteration 119, loss = 0.29535695\n",
            "Iteration 120, loss = 0.29221066\n",
            "Iteration 121, loss = 0.29192378\n",
            "Iteration 122, loss = 0.29108875\n",
            "Iteration 123, loss = 0.29144521\n",
            "Iteration 124, loss = 0.28906068\n",
            "Iteration 125, loss = 0.28714485\n",
            "Iteration 126, loss = 0.28716831\n",
            "Iteration 127, loss = 0.28841903\n",
            "Iteration 128, loss = 0.28841229\n",
            "Iteration 129, loss = 0.28888385\n",
            "Iteration 130, loss = 0.28866203\n",
            "Iteration 131, loss = 0.28438790\n",
            "Iteration 132, loss = 0.28453139\n",
            "Iteration 133, loss = 0.28494981\n",
            "Iteration 134, loss = 0.28449471\n",
            "Iteration 135, loss = 0.28442531\n",
            "Iteration 136, loss = 0.28331782\n",
            "Iteration 137, loss = 0.29127041\n",
            "Iteration 138, loss = 0.28453324\n",
            "Iteration 139, loss = 0.28292190\n",
            "Iteration 140, loss = 0.28104340\n",
            "Iteration 141, loss = 0.27855572\n",
            "Iteration 142, loss = 0.27891165\n",
            "Iteration 143, loss = 0.27779191\n",
            "Iteration 144, loss = 0.27958512\n",
            "Iteration 145, loss = 0.28957801\n",
            "Iteration 146, loss = 0.28648350\n",
            "Iteration 147, loss = 0.28672666\n",
            "Iteration 148, loss = 0.28543970\n",
            "Iteration 149, loss = 0.28243493\n",
            "Iteration 150, loss = 0.28050964\n",
            "Iteration 151, loss = 0.27813026\n",
            "Iteration 152, loss = 0.28227369\n",
            "Iteration 153, loss = 0.27783343\n",
            "Iteration 154, loss = 0.27742276\n",
            "Iteration 155, loss = 0.27808873\n",
            "Iteration 156, loss = 0.27509282\n",
            "Iteration 157, loss = 0.27885486\n",
            "Iteration 158, loss = 0.28756891\n",
            "Iteration 159, loss = 0.28437314\n",
            "Iteration 160, loss = 0.28354997\n",
            "Iteration 161, loss = 0.27988217\n",
            "Iteration 162, loss = 0.27584858\n",
            "Iteration 163, loss = 0.27666071\n",
            "Iteration 164, loss = 0.27283806\n",
            "Iteration 165, loss = 0.27144009\n",
            "Iteration 166, loss = 0.27162292\n",
            "Iteration 167, loss = 0.27916536\n",
            "Iteration 168, loss = 0.27706422\n",
            "Iteration 169, loss = 0.27313127\n",
            "Iteration 170, loss = 0.27248491\n",
            "Iteration 171, loss = 0.27465572\n",
            "Iteration 172, loss = 0.27152157\n",
            "Iteration 173, loss = 0.27003245\n",
            "Iteration 174, loss = 0.27332534\n",
            "Iteration 175, loss = 0.27398565\n",
            "Iteration 176, loss = 0.27049856\n",
            "Iteration 177, loss = 0.27378136\n",
            "Iteration 178, loss = 0.26974619\n",
            "Iteration 179, loss = 0.27131272\n",
            "Iteration 180, loss = 0.26514879\n",
            "Iteration 181, loss = 0.26546435\n",
            "Iteration 182, loss = 0.26931920\n",
            "Iteration 183, loss = 0.27486616\n",
            "Iteration 184, loss = 0.27698754\n",
            "Iteration 185, loss = 0.26909898\n",
            "Iteration 186, loss = 0.26469894\n",
            "Iteration 187, loss = 0.26470596\n",
            "Iteration 188, loss = 0.26737859\n",
            "Iteration 189, loss = 0.26673162\n",
            "Iteration 190, loss = 0.26809591\n",
            "Iteration 191, loss = 0.26599371\n",
            "Iteration 192, loss = 0.26583407\n",
            "Iteration 193, loss = 0.26654350\n",
            "Iteration 194, loss = 0.27659561\n",
            "Iteration 195, loss = 0.27730986\n",
            "Iteration 196, loss = 0.27411327\n",
            "Iteration 197, loss = 0.26594368\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "['Abnormal' 'Abnormal' 'Normal' 'Normal' 'Abnormal' 'Normal' 'Normal'\n",
            " 'Normal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal'\n",
            " 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal'\n",
            " 'Normal' 'Abnormal' 'Abnormal' 'Abnormal' 'Normal' 'Abnormal' 'Normal'\n",
            " 'Abnormal' 'Abnormal' 'Abnormal' 'Normal' 'Normal' 'Abnormal' 'Normal'\n",
            " 'Abnormal' 'Abnormal' 'Abnormal' 'Normal' 'Normal' 'Normal' 'Abnormal'\n",
            " 'Abnormal' 'Abnormal' 'Abnormal' 'Normal' 'Abnormal' 'Normal' 'Abnormal'\n",
            " 'Abnormal' 'Normal' 'Abnormal' 'Normal' 'Abnormal' 'Abnormal' 'Abnormal'\n",
            " 'Normal' 'Abnormal' 'Normal' 'Abnormal' 'Abnormal' 'Abnormal' 'Normal'\n",
            " 'Abnormal' 'Normal' 'Abnormal' 'Normal' 'Abnormal' 'Normal' 'Normal'\n",
            " 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal'\n",
            " 'Normal' 'Normal' 'Normal' 'Normal']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm35n4KPNrER",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "785042b4-5b8b-456f-aa0a-b31455d3f21d"
      },
      "source": [
        "accuracy_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7948717948717948"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAU1FOLxOM8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm=confusion_matrix(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEgntDKlN4_A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b3905297-5bf1-469c-e3b3-5acd10da1937"
      },
      "source": [
        "sns.heatmap(cm,center=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD4CAYAAACt8i4nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX7Dru5QKNKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#solver optimizes weight\n",
        "clf1=MLPClassifier(activation='logistic',hidden_layer_sizes=(100,100,100),max_iter=500,alpha=0.0001,\n",
        "                  solver='adam',verbose=10,random_state=21,tol=0.000000001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U-xjjOvKl1L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f767a069-4b43-4f6d-e134-1ed89350b42b"
      },
      "source": [
        "clf1.fit(x_train,y_train)\n",
        "y_pred=clf1.predict(x_test)\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.69128611\n",
            "Iteration 2, loss = 0.64742290\n",
            "Iteration 3, loss = 0.63334559\n",
            "Iteration 4, loss = 0.62873273\n",
            "Iteration 5, loss = 0.63184142\n",
            "Iteration 6, loss = 0.63465884\n",
            "Iteration 7, loss = 0.63544125\n",
            "Iteration 8, loss = 0.63261989\n",
            "Iteration 9, loss = 0.62728533\n",
            "Iteration 10, loss = 0.62137801\n",
            "Iteration 11, loss = 0.61903763\n",
            "Iteration 12, loss = 0.61803957\n",
            "Iteration 13, loss = 0.61688999\n",
            "Iteration 14, loss = 0.61422762\n",
            "Iteration 15, loss = 0.61063182\n",
            "Iteration 16, loss = 0.60646817\n",
            "Iteration 17, loss = 0.60192509\n",
            "Iteration 18, loss = 0.59671365\n",
            "Iteration 19, loss = 0.59084413\n",
            "Iteration 20, loss = 0.58462891\n",
            "Iteration 21, loss = 0.57801561\n",
            "Iteration 22, loss = 0.57001637\n",
            "Iteration 23, loss = 0.56122922\n",
            "Iteration 24, loss = 0.55347504\n",
            "Iteration 25, loss = 0.54481423\n",
            "Iteration 26, loss = 0.53359724\n",
            "Iteration 27, loss = 0.52066910\n",
            "Iteration 28, loss = 0.50720141\n",
            "Iteration 29, loss = 0.49546957\n",
            "Iteration 30, loss = 0.48434112\n",
            "Iteration 31, loss = 0.46989308\n",
            "Iteration 32, loss = 0.45476717\n",
            "Iteration 33, loss = 0.44396662\n",
            "Iteration 34, loss = 0.43726108\n",
            "Iteration 35, loss = 0.42804717\n",
            "Iteration 36, loss = 0.41493517\n",
            "Iteration 37, loss = 0.40266139\n",
            "Iteration 38, loss = 0.39484069\n",
            "Iteration 39, loss = 0.39186439\n",
            "Iteration 40, loss = 0.38478850\n",
            "Iteration 41, loss = 0.37321052\n",
            "Iteration 42, loss = 0.36487164\n",
            "Iteration 43, loss = 0.36280753\n",
            "Iteration 44, loss = 0.35952471\n",
            "Iteration 45, loss = 0.35191730\n",
            "Iteration 46, loss = 0.34388137\n",
            "Iteration 47, loss = 0.34331348\n",
            "Iteration 48, loss = 0.33977007\n",
            "Iteration 49, loss = 0.33315645\n",
            "Iteration 50, loss = 0.33982256\n",
            "Iteration 51, loss = 0.34443025\n",
            "Iteration 52, loss = 0.33302630\n",
            "Iteration 53, loss = 0.32545253\n",
            "Iteration 54, loss = 0.32971484\n",
            "Iteration 55, loss = 0.32298498\n",
            "Iteration 56, loss = 0.32210221\n",
            "Iteration 57, loss = 0.33313581\n",
            "Iteration 58, loss = 0.32813705\n",
            "Iteration 59, loss = 0.31924325\n",
            "Iteration 60, loss = 0.32093264\n",
            "Iteration 61, loss = 0.31893481\n",
            "Iteration 62, loss = 0.31614647\n",
            "Iteration 63, loss = 0.31494848\n",
            "Iteration 64, loss = 0.31402066\n",
            "Iteration 65, loss = 0.31474079\n",
            "Iteration 66, loss = 0.31626870\n",
            "Iteration 67, loss = 0.31400831\n",
            "Iteration 68, loss = 0.31167774\n",
            "Iteration 69, loss = 0.31319245\n",
            "Iteration 70, loss = 0.31652213\n",
            "Iteration 71, loss = 0.31488585\n",
            "Iteration 72, loss = 0.30995367\n",
            "Iteration 73, loss = 0.30906273\n",
            "Iteration 74, loss = 0.31397832\n",
            "Iteration 75, loss = 0.31171955\n",
            "Iteration 76, loss = 0.30618122\n",
            "Iteration 77, loss = 0.31189485\n",
            "Iteration 78, loss = 0.31956458\n",
            "Iteration 79, loss = 0.31421995\n",
            "Iteration 80, loss = 0.30549981\n",
            "Iteration 81, loss = 0.30796751\n",
            "Iteration 82, loss = 0.30966037\n",
            "Iteration 83, loss = 0.30558341\n",
            "Iteration 84, loss = 0.30417750\n",
            "Iteration 85, loss = 0.30715930\n",
            "Iteration 86, loss = 0.30613771\n",
            "Iteration 87, loss = 0.30313373\n",
            "Iteration 88, loss = 0.30292717\n",
            "Iteration 89, loss = 0.30461856\n",
            "Iteration 90, loss = 0.30529406\n",
            "Iteration 91, loss = 0.31562448\n",
            "Iteration 92, loss = 0.31401468\n",
            "Iteration 93, loss = 0.30239944\n",
            "Iteration 94, loss = 0.30781611\n",
            "Iteration 95, loss = 0.31311333\n",
            "Iteration 96, loss = 0.30605558\n",
            "Iteration 97, loss = 0.30145619\n",
            "Iteration 98, loss = 0.30222271\n",
            "Iteration 99, loss = 0.30169018\n",
            "Iteration 100, loss = 0.30135065\n",
            "Iteration 101, loss = 0.29872947\n",
            "Iteration 102, loss = 0.30160498\n",
            "Iteration 103, loss = 0.29837683\n",
            "Iteration 104, loss = 0.30017376\n",
            "Iteration 105, loss = 0.30474507\n",
            "Iteration 106, loss = 0.29962924\n",
            "Iteration 107, loss = 0.29887484\n",
            "Iteration 108, loss = 0.30261602\n",
            "Iteration 109, loss = 0.30204305\n",
            "Iteration 110, loss = 0.29954989\n",
            "Iteration 111, loss = 0.29801566\n",
            "Iteration 112, loss = 0.29573174\n",
            "Iteration 113, loss = 0.30163217\n",
            "Iteration 114, loss = 0.30113420\n",
            "Iteration 115, loss = 0.29804074\n",
            "Iteration 116, loss = 0.29633053\n",
            "Iteration 117, loss = 0.29601248\n",
            "Iteration 118, loss = 0.29444861\n",
            "Iteration 119, loss = 0.29776662\n",
            "Iteration 120, loss = 0.29683546\n",
            "Iteration 121, loss = 0.29519764\n",
            "Iteration 122, loss = 0.29376152\n",
            "Iteration 123, loss = 0.29360336\n",
            "Iteration 124, loss = 0.29345256\n",
            "Iteration 125, loss = 0.29241633\n",
            "Iteration 126, loss = 0.29261167\n",
            "Iteration 127, loss = 0.29556834\n",
            "Iteration 128, loss = 0.29374877\n",
            "Iteration 129, loss = 0.29105820\n",
            "Iteration 130, loss = 0.29026547\n",
            "Iteration 131, loss = 0.29006268\n",
            "Iteration 132, loss = 0.29061781\n",
            "Iteration 133, loss = 0.28969308\n",
            "Iteration 134, loss = 0.28865552\n",
            "Iteration 135, loss = 0.28869500\n",
            "Iteration 136, loss = 0.28970791\n",
            "Iteration 137, loss = 0.28772861\n",
            "Iteration 138, loss = 0.29701628\n",
            "Iteration 139, loss = 0.29565421\n",
            "Iteration 140, loss = 0.28786407\n",
            "Iteration 141, loss = 0.28882249\n",
            "Iteration 142, loss = 0.29250866\n",
            "Iteration 143, loss = 0.29051233\n",
            "Iteration 144, loss = 0.28971934\n",
            "Iteration 145, loss = 0.28753530\n",
            "Iteration 146, loss = 0.28746427\n",
            "Iteration 147, loss = 0.28981943\n",
            "Iteration 148, loss = 0.29868739\n",
            "Iteration 149, loss = 0.29338853\n",
            "Iteration 150, loss = 0.28798632\n",
            "Iteration 151, loss = 0.28988198\n",
            "Iteration 152, loss = 0.28677364\n",
            "Iteration 153, loss = 0.28805634\n",
            "Iteration 154, loss = 0.29239564\n",
            "Iteration 155, loss = 0.28932261\n",
            "Iteration 156, loss = 0.28519109\n",
            "Iteration 157, loss = 0.28582990\n",
            "Iteration 158, loss = 0.28479116\n",
            "Iteration 159, loss = 0.28698819\n",
            "Iteration 160, loss = 0.28945065\n",
            "Iteration 161, loss = 0.28796670\n",
            "Iteration 162, loss = 0.28160674\n",
            "Iteration 163, loss = 0.28091598\n",
            "Iteration 164, loss = 0.28000814\n",
            "Iteration 165, loss = 0.27984314\n",
            "Iteration 166, loss = 0.27982880\n",
            "Iteration 167, loss = 0.27901698\n",
            "Iteration 168, loss = 0.29012357\n",
            "Iteration 169, loss = 0.29523485\n",
            "Iteration 170, loss = 0.28421148\n",
            "Iteration 171, loss = 0.27966783\n",
            "Iteration 172, loss = 0.28220114\n",
            "Iteration 173, loss = 0.28104845\n",
            "Iteration 174, loss = 0.28028912\n",
            "Iteration 175, loss = 0.28829687\n",
            "Iteration 176, loss = 0.28293808\n",
            "Iteration 177, loss = 0.27876970\n",
            "Iteration 178, loss = 0.28754466\n",
            "Iteration 179, loss = 0.28914111\n",
            "Iteration 180, loss = 0.28001384\n",
            "Iteration 181, loss = 0.27703247\n",
            "Iteration 182, loss = 0.28385387\n",
            "Iteration 183, loss = 0.28243000\n",
            "Iteration 184, loss = 0.27715300\n",
            "Iteration 185, loss = 0.27983259\n",
            "Iteration 186, loss = 0.27994262\n",
            "Iteration 187, loss = 0.27983049\n",
            "Iteration 188, loss = 0.27932782\n",
            "Iteration 189, loss = 0.27662109\n",
            "Iteration 190, loss = 0.27517503\n",
            "Iteration 191, loss = 0.27730264\n",
            "Iteration 192, loss = 0.27610581\n",
            "Iteration 193, loss = 0.27868122\n",
            "Iteration 194, loss = 0.27484463\n",
            "Iteration 195, loss = 0.27977806\n",
            "Iteration 196, loss = 0.29091216\n",
            "Iteration 197, loss = 0.27828628\n",
            "Iteration 198, loss = 0.27758465\n",
            "Iteration 199, loss = 0.30824238\n",
            "Iteration 200, loss = 0.30709583\n",
            "Iteration 201, loss = 0.27940371\n",
            "Iteration 202, loss = 0.27954637\n",
            "Iteration 203, loss = 0.28737048\n",
            "Iteration 204, loss = 0.28286190\n",
            "Iteration 205, loss = 0.27544179\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "['Abnormal' 'Abnormal' 'Abnormal' 'Normal' 'Abnormal' 'Normal' 'Normal'\n",
            " 'Normal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal'\n",
            " 'Abnormal' 'Abnormal' 'Normal' 'Abnormal' 'Abnormal' 'Abnormal' 'Normal'\n",
            " 'Abnormal' 'Abnormal' 'Normal' 'Normal' 'Abnormal' 'Normal' 'Abnormal'\n",
            " 'Abnormal' 'Abnormal' 'Abnormal' 'Normal' 'Abnormal' 'Abnormal'\n",
            " 'Abnormal' 'Abnormal' 'Abnormal' 'Normal' 'Normal' 'Normal' 'Abnormal'\n",
            " 'Abnormal' 'Abnormal' 'Abnormal' 'Normal' 'Abnormal' 'Normal' 'Abnormal'\n",
            " 'Abnormal' 'Normal' 'Abnormal' 'Normal' 'Abnormal' 'Abnormal' 'Abnormal'\n",
            " 'Normal' 'Normal' 'Normal' 'Abnormal' 'Abnormal' 'Abnormal' 'Normal'\n",
            " 'Abnormal' 'Normal' 'Abnormal' 'Normal' 'Abnormal' 'Normal' 'Normal'\n",
            " 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal'\n",
            " 'Normal' 'Normal' 'Normal' 'Normal']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcYGVvh6NjWX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cb7253b4-4ff5-4557-c7a6-ce9d55591e91"
      },
      "source": [
        "accuracy_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8461538461538461"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMJ6UyT0OXnd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm=confusion_matrix(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYAJUr6cOc_F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "86d2b5f2-cc73-4c45-9531-1b28b1f32f4a"
      },
      "source": [
        "sns.heatmap(cm,center=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD8CAYAAAA2Y2wxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqzRSRtGLV0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf2=MLPClassifier(activation='relu',hidden_layer_sizes=(100,100,100),max_iter=500,alpha=0.0001,\n",
        "                  solver='lbfgs',verbose=10,random_state=21,tol=0.000000001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgNve4y9Lgwx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "ab7aaa4d-5802-42da-92b8-8648939f2198"
      },
      "source": [
        "clf2.fit(x_train,y_train)\n",
        "y_pred=clf2.predict(x_test)\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal'\n",
            " 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal'\n",
            " 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal'\n",
            " 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal'\n",
            " 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal'\n",
            " 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal'\n",
            " 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal'\n",
            " 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal'\n",
            " 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal'\n",
            " 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal'\n",
            " 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal'\n",
            " 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal'\n",
            " 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal' 'Abnormal']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT7g2ll6N14q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "956b1383-20e9-433b-9ebf-95a5fa6c7172"
      },
      "source": [
        "accuracy_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6794871794871795"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVubO1P0MOam",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7c310a57-dbdc-4a90-9d70-6b500d63eab4"
      },
      "source": [
        "cm=confusion_matrix(y_test,y_pred)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[53,  0],\n",
              "       [25,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCtiZxX6OuTU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "7daa4f50-b053-44a8-ff7b-7efdbcaf3b24"
      },
      "source": [
        "sns.heatmap(cm,center=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD4CAYAAACt8i4nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\np5B+3C6/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}